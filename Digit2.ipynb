{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the codes in Module 10\n",
    "# load data\n",
    "import pandas as pd\n",
    "train_data = pd.read_csv(\"./data/train.csv\")\n",
    "test_data = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take target out of training set\n",
    "Y = train_data['label']\n",
    "train_data = train_data.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove the features that are all zeros\n",
    "total_data = train_data\n",
    "total_data = total_data.append(test_data)\n",
    "for col in total_data.columns:\n",
    "    if len(total_data[total_data[col] == 0]) == len(total_data[col]):\n",
    "        train_data = train_data.drop([col], axis=1)\n",
    "        test_data = test_data.drop([col], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# min-max scaling\n",
    "train_data = (train_data - train_data.min()) / (train_data.max() - train_data.min())\n",
    "test_data = (test_data - test_data.min()) / (test_data.max() - test_data.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def countMissing(data):\n",
    "    missing = data.columns[data.isnull().any()].tolist()\n",
    "    return missing\n",
    "misTrain = countMissing(train_data)\n",
    "misTest = countMissing(test_data)\n",
    "misTotal = list(set().union(misTrain, misTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imputation(data, column, value):\n",
    "    data.loc[data[column].isnull(), column] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(misTrain, len(misTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(misTest, len(misTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ele in misTrain:\n",
    "    imputation(train_data, ele, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ele in misTest:\n",
    "    imputation(test_data, ele, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One-Vs-Rest with regularized logistic regression models\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import linear_model\n",
    "# edit by Keith: solver='liblinear'\n",
    "res = OneVsRestClassifier(linear_model.LogisticRegression(penalty='l1', solver='liblinear')).fit(train_data, Y).predict(test_data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One-Vs-One with regularized logistic regression models\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn import linear_model\n",
    "# edit by Keith: solver='liblinear'\n",
    "res = OneVsOneClassifier(linear_model.LogisticRegression(penalty='l1', solver='liblinear')).fit(train_data, Y).predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit by Keith: cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "alphas = [0.01, 0.1, 1.0, 10]\n",
    "regs = [\"l1\", \"l2\"]\n",
    "scores = []\n",
    "param = []\n",
    "for alpha in alphas:\n",
    "    for reg in regs:\n",
    "        lm = OneVsRestClassifier(linear_model.LogisticRegression(penalty=reg, C=alpha, solver='liblinear'))\n",
    "        scores.append(cross_val_score(lm, train_data, Y, scoring=\"accuracy\", cv=2).mean())\n",
    "        param.append([alpha, reg])\n",
    "scores = pd.DataFrame({'parameter': param, 'score': scores})\n",
    "print(scores.sort_values(by = 'score', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "alphas = [0.01, 0.1, 1.0, 10]\n",
    "regs = [\"l1\", \"l2\"]\n",
    "scores = []\n",
    "param = []\n",
    "for alpha in alphas:\n",
    "    for reg in regs:\n",
    "        lm = OneVsOneClassifier(linear_model.LogisticRegression(penalty=reg, C=alpha, solver='liblinear'))\n",
    "        scores.append(cross_val_score(lm, train_data, Y, scoring=\"accuracy\", cv = 2).mean())\n",
    "        param.append([alpha, reg])\n",
    "scores = pd.DataFrame({'parameter': param, 'score': scores})\n",
    "print(scores.sort_values(by = 'score', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One-Vs-Rest with regularized logistic regression models\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import linear_model\n",
    "res = OneVsRestClassifier(linear_model.LogisticRegression(penalty=\"l1\", C=1.0, solver='liblinear')).fit(train_data, Y).predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One-Vs-One with regularized logistic regression models\n",
    "from sklearn.multiclass import OneVsOneClassifierb\n",
    "from sklearn import linear_model\n",
    "res = OneVsOneClassifier(linear_model.LogisticRegression(penalty=\"l2\", C=1.0, solver='liblinear')).fit(train_data, Y).predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train regularized softmax regression model\n",
    "from sklearn import linear_model\n",
    "lm = linear_model.LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "lm.fit(train_data, Y)\n",
    "res = lm.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# edit by Keith: cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "alphas = [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1.0, 3.0, 10, 30, 100, 300, 1000, 3000]\n",
    "scores = []\n",
    "param = []\n",
    "for alpha in alphas:\n",
    "    lm = linear_model.LogisticRegression(C=alpha, multi_class='multinomial', solver='lbfgs')\n",
    "    scores.append(cross_val_score(lm, train_data, Y, scoring=\"accuracy\", cv=10).mean())\n",
    "    param.append([alpha])\n",
    "scores = pd.DataFrame({'parameter': param, 'score': scores})\n",
    "print(scores.sort_values(by = 'score', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train regularized softmax regression model\n",
    "from sklearn import linear_model\n",
    "lm = linear_model.LogisticRegression(C = 0.3, multi_class = 'multinomial', solver = 'lbfgs')\n",
    "lm.fit(train_data, Y)\n",
    "res = lm.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "# RBF function\n",
    "def rbf(data, centers, sigma):\n",
    "    res = np.ndarray(shape = (len(data), len(centers)))\n",
    "    i = 0\n",
    "    for row in data:\n",
    "        tmp = []\n",
    "        for center in centers:\n",
    "            tmp.append(math.exp(-1.0 * sum(np.square(row - center)) / (2 * sigma * sigma)))\n",
    "        res[i, :] = tmp\n",
    "        i = i + 1\n",
    "    return res\n",
    "# select k centers from data\n",
    "def selectCenters(data, k):\n",
    "    tmp = np.random.choice(len(data), k)\n",
    "    return data[tmp,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cross validation on regularized softmax regression\n",
    "# edit by Keith: cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "alphas = [0.1, 1.0, 10]\n",
    "sigmas = [1.0, 2.0, 4.0]\n",
    "Ks = [100, 400, 800, 1600]\n",
    "scores = []\n",
    "param = []\n",
    "for K in Ks:\n",
    "    centers = selectCenters(train_data.as_matrix(), K)\n",
    "    for sigma in sigmas:\n",
    "        rbfX = rbf(train_data.as_matrix(), centers, sigma)\n",
    "        for a in alphas:\n",
    "            lm = linear_model.LogisticRegression(multi_class = 'multinomial', solver = 'lbfgs', C = a)\n",
    "            scores.append(cross_val_score(lm, rbfX, Y, scoring=\"accuracy\", cv = 10).mean())\n",
    "            param.append([K, sigma, a])\n",
    "scores = pd.DataFrame({'parameter': param, 'score': scores})\n",
    "print(scores.sort_values(by = 'score', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "centers = selectCenters(train_data.as_matrix(), 1600)\n",
    "rbfX = rbf(train_data.as_matrix(), centers, 4.0)\n",
    "rbfTest = rbf(test_data.as_matrix(), centers, 4.0)\n",
    "lm = linear_model.LogisticRegression(multi_class = 'multinomial', solver = 'lbfgs', C = 10)\n",
    "lm.fit(rbfX, Y)\n",
    "res = lm.predict(rbfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# edit by Keith: cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "alphas = [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1.0, 3.0, 10, 30, 100, 300, 1000, 3000]\n",
    "Ks = [10, 100, 500]\n",
    "scores = []\n",
    "param = []\n",
    "for K in Ks: \n",
    "    pca = PCA(n_components = K, svd_solver='arpack')\n",
    "    pca.fit(train_data)\n",
    "    pca_train = pca.transform(train_data)\n",
    "    for alpha in alphas:\n",
    "        lm = linear_model.LogisticRegression(C = alpha, multi_class = 'multinomial', solver = 'lbfgs')\n",
    "        scores.append(cross_val_score(lm, pca_train, Y, scoring=\"accuracy\", cv = 10).mean())\n",
    "        param.append([K, alpha])\n",
    "scores = pd.DataFrame({'parameter': param, 'score': scores})\n",
    "print(scores.sort_values(by = 'score', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 500, svd_solver='arpack')\n",
    "pca.fit(train_data)\n",
    "pca_train = pca.transform(train_data)\n",
    "pca_test = pca.transform(test_data)\n",
    "lm = linear_model.LogisticRegression(C = 0.3, multi_class = 'multinomial', solver = 'lbfgs')\n",
    "lm.fit(pca_train, Y)\n",
    "res = lm.predict(pca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# edit by Keith: cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "nigs = [1, 10, 20]\n",
    "scores = []\n",
    "param = []\n",
    "for n in nigs:\n",
    "    neigh = KNeighborsClassifier(n_neighbors = n)\n",
    "    scores.append(cross_val_score(neigh, train_data, Y, scoring=\"accuracy\", cv = 10).mean())\n",
    "    param.append([n])\n",
    "scores = pd.DataFrame({'parameter': param, 'score': scores})\n",
    "print(scores.sort_values(by = 'score', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors = 1)\n",
    "neigh.fit(train_data, Y)\n",
    "res = neigh.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save predictions\n",
    "sample_data = pd.read_csv(\"./data/sample_submission.csv\")\n",
    "sample_data['Label'] = res\n",
    "sample_data.to_csv('./prediction.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.6 64-bit",
   "name": "python366jvsc74a57bd0f7291e4b392a32fbfa525b87d1bbd0a3d888adf3d0deca0c205c61b9e7284b82"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "8c63cf580b891297294b3de353c4126d669a3d9a70f8c3e9fd5605aca4094b44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
